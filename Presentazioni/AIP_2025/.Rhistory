ggplot(X,aes(Age_mean)) + geom_density(fill=COLORI[2],color=COLORI[2],alpha=.5) + ggtitle("[C]") + ylab(""),
ggplot(X,aes(PB_operationalization)) + geom_bar(fill=COLORI[4],color=COLORI[4],alpha=.5) + ggtitle("[D]") + scale_x_continuous( breaks = c(1,2) ) + ylab(""),
ncol = 2
)
plot_grid(
ggforest(X1,color=TRUE,jj=2,alpha=.6)+ggtitle("[A]"),
ggfunnel(X1,color = TRUE)+ggtitle("[B]")
)
X1 <- escalc(measure = "ZCOR",ri=corr_PB_LON_ww,ni=Sample_n,data=X)
X1$nstudy <- factor(X1$Study_ID)
plot_grid(
ggforest(X1,color=TRUE,jj=2,alpha=.6)+ggtitle("[A]"),
ggfunnel(X1,color = TRUE)+ggtitle("[B]")
)
X1 <- escalc(measure = "ZCOR",ri=corr_PB_LON_ww,ni=Sample_n,data=X)
library(metafor)
X1 <- escalc(measure = "ZCOR",ri=corr_PB_LON_ww,ni=Sample_n,data=X)
X1$nstudy <- factor(X1$Study_ID)
plot_grid(
ggforest(X1,color=TRUE,jj=2,alpha=.6)+ggtitle("[A]"),
ggfunnel(X1,color = TRUE)+ggtitle("[B]")
)
P00 <- subset(Priors, model == "M00" )
rm(list=ls())
INIZIO <- Sys.time()
# +++++++++++++++++++++++++++++++++++++
main <- "/Users/ambraperugini/Documents/Work/projects/Risultati_PB/"
# main <- "~/lavori/benedetta/meta24/"
if (grepl("kolmogorov",Sys.info()["user"])) main <- gsub("~/","~/MEGAsync/",main)
if (grepl("cox",Sys.info()["user"])) main <- gsub("~/","~/MEGA/",main)
datadir <- paste(main,"data/",sep="")
Rdir <- paste(main,"Rcodes/",sep="")
#if (!exists(Rdir)) dir.create(Rdir)
# KUtils::pulizia(paste(main,"knitr/",sep=""),c("Rnw","bib","pdf")) #,TRUE, rm.cache=TRUE)
D <- format(Sys.Date(),"%d/%m/%Y")
nrep <- 5 #KUtils::nreport(paste(main,"knitr/",sep=""))
R <- paste("Report 0",nrep,sep="")
report <- paste(R,"-",D,collapse="")
R <- "Meta-analisi: comportamento prosociale e loneliness"
esegui <- FALSE
ITER <- 3e3
NCHAINS <- 4
LEVEL <- .9
PROBS <- c( (1-LEVEL)/2,1-(1-LEVEL)/2 )
TEXTCEX <- 11
SEED <- 3
NDRAWS <- 30
#purl(paste0(main,"knitr/TKI04.Rnw"), output=paste0(Rdir,"TKI04.R"))
```
## ++++++++++++++++++++++++++++++++++
#' @title Grafico correlazioni
#' @param RR = correlation matrix
#' @param U = vettore con i margini del grafico
plot_correlation <- function(RR,values=FALSE,textsize=12,angle=0, corrsize=4, U=c(0,-2,-.5,-2)) {
require(ggplot2)
require(reshape2)
RR <- melt(RR)
NAME <- "Correlation"
GGcor <- ggplot(RR,aes(Var2,Var1,fill=value))+geom_tile()+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",midpoint =0, space = "Lab",name=NAME)+
xlab("")+ylab("")+coord_fixed()+
theme(plot.margin = unit(U, "cm"),
text=element_text(size=textsize),
axis.text.x=element_text(angle=angle),
legend.text = element_text(size = textsize),legend.title = element_text(size = textsize))
if (values) {
GGcor <- GGcor + geom_text(aes(Var2, Var1, label = value), color = "black", size = corrsize )
}
print(GGcor)
}
# +++++++++++++++++++++++++++
#' @title Intervallo di confidenza della correlazione
#' @param r = correlation
#' @param n = sample size
#' @param alpha = alpha level
r_confidence_interval <- function(r, n, alpha = .05) {
z <- 0.5 * log((1+r)/(1-r))
zq <- qnorm(1-alpha/2)
zlow <- z-zq*sqrt(1/(n-3))
zup <- z+zq*sqrt(1/(n-3))
rCI <- c( (exp(2*zlow)-1) / (exp(2*zlow) + 1),
(exp(2*zup)-1) / (exp(2*zup) + 1) )
return(rCI)
}
# +++++++++++++++++++++++++++++++++++
#' @title handle_warning
#' @description salva i warnings in una lista
#' @return restituisce una lista \code{warning_list} contenente i warnings
handle_warning <- function(warning) {
warnings_list <- c()
warnings_list <<- c(warnings_list, warning)
invokeRestart("muffleWarning")
}
# +++++++++ funzione colori default
gg_color_hue <- function(n) {
hues = seq(15, 375, length = n + 1)
hcl(h = hues, l = 65, c = 100)[1:n]
}
# +++++++++++++++++++++++++++++++++++++
#' @title ggfunnel
#' @description produce il funnel plot con ggplot
#' @param X = dataframe deve avere due colonne specifiche: \code{yi} e \code{vi}
ggfunnel <- function(X, color = FALSE, show.legend=FALSE) {
require(ggplot2)
X$effsize <- X$yi
X$effsize.se <- sqrt(X$vi)
estimate <- with(X,mean(effsize,na.rm = TRUE))
se <- with(X,mean(effsize.se,na.rm=TRUE))
se.seq <- with(X,seq(0,max(effsize.se,na.rm = TRUE)*1.1, length.out = length(effsize.se)))
#Compute vectors of the lower-limit and upper limit values for
#the 95% CI region
ll95 = estimate-(1.96*se.seq)
ul95 = estimate+(1.96*se.seq)
#Do this for a 99% CI region too
ll99 = estimate-(3.29*se.seq)
ul99 = estimate+(3.29*se.seq)
#And finally, calculate the confidence interval for your meta-analytic estimate
meanll95 = estimate-(1.96*se)
meanul95 = estimate+(1.96*se)
#Put all calculated values into one data frame
#You might get a warning about '...row names were found from a short variable...'
#You can ignore it.
dfCI = data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)
#YLIM <- c((max(X$effsize,na.rm=TRUE)-estimate)-max(X$effsize,na.rm = TRUE),max(X$effsize,na.rm=TRUE))
GG <- ggplot(dfCI) + scale_x_reverse()+ coord_flip()+geom_hline(yintercept = estimate)+geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted') + geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted') + geom_line(aes(x = se.seq, y = ll99), linetype = 'dashed') + geom_line(aes(x = se.seq, y = ul99), linetype = 'dashed') + geom_ribbon(aes(x=se.seq,ymin = ul99, ymax = ll99),fill="#dfe3ee",alpha=.3) + geom_ribbon(aes(x=se.seq,ymin = ul95, ymax = ll95),fill="#8b9dc3",alpha=.3) + xlab("Standard error")+ylab("Effect size") + theme_bw()
if (color) {
GG <- GG + geom_point(aes(x=effsize.se,y=effsize,colour=factor(nstudy)),data=X)
} else {
GG <- GG + geom_point(aes(x=effsize.se,y=effsize),data=X)
}
if (!show.legend) {
GG <- GG + guides(colour=FALSE)
}
}
# +++++++++++++++++++++++++++++
#' @name tprob
#' @description Calcola la densità della t tra due estremi dati con la funzione \code{pTF()} del pacchetto \code{gamlss.dist}.
#' @param low = valore inferiore dell'intervallo
#' @param up = valore superiore dell'intervallo
#' @param mu = media
#' @param sigma = deviazione standard
#' @param nu = gradi di liberta
tprob <- function(low, up, mu, sigma = 1, nu = 3 ) {
require(gamlss.dist)
if (low>up) {
warning("inverto low e up")
t_up <- low
low <- up
up <- t_up
}
P <- pTF(up,mu,sigma = sigma, nu = nu )- pTF(low,mu,sigma = sigma, nu = nu )
return(P)
}
## +++++++++++++++++++++++++++++++++++++
#' @title extract_priors_param
#' @description estrae i parametri delle prior dalle stringhe di brms
#' @param h = stringa
#' @return restituisce una lista di quattro elementi: il nome R della funzione di densità (\code{funct}), il nome esteso (\coed{name}), il vettore dei parametri (\code{par}) e l'etichetta in formato LateX (\code{label})
extract_priors_param <- function(h) {
input <- h
(h <- gsub("\\)",";",gsub("\\(",";",h)))
(h <- strsplit(h, ";")[[1]])
name <- h[1]
pars <- as.numeric( strsplit(h[2],",")[[1]] )
if (!grepl("gamma",name) & !grepl("normal",name) & !grepl("student",name) & !grepl("lkj",name) & !grepl("beta",name)) {
warning(paste0("non so gestire ",input),"\n")
funct <- name <- label <- NULL
}
if (grepl("gamma",name)) {
funct <- "dgamma"
name <- "Gamma"
label <- paste0( name, "(",h[2],")")
}
if (grepl("normal",name)) {
funct <- "dnorm"
name <- "Normal"
label <- paste0( name, "(",h[2],")")
}
if (grepl("beta",name)) {
funct <- "dbeta"
name <- "Beta"
label <- paste0( name, "(",h[2],")")
}
if (grepl("student",name)) {
funct <- "gamlss.dist::dTF"
name <- "Student's $t$"
label <- paste0( name, "(",h[2],")")
}
if (grepl("lkj",name)) {
funct <- "rethinking::dlkjcorr"
name <- "LKJ"
label <- paste0(name,"(",h[2],")")
}
return(list(funct=funct, name=name, pars=pars, label=label))
}
## +++++++++++++++++++++++++++++++++++++
#' @name printl
#' @description Stampa 0.001 quando l'evidenza relativa è molto piccola
#' @param l relative likelihood
printl <- function(l) {
return( ifelse(l < .001, "$<.001$", l ) )
}
rm(list=ls())
INIZIO <- Sys.time()
rm(list=ls())
INIZIO <- Sys.time()
# +++++++++++++++++++++++++++++++++++++
main <- "/Users/ambraperugini/Documents/Work/projects/Risultati_PB/"
# main <- "~/lavori/benedetta/meta24/"
if (grepl("kolmogorov",Sys.info()["user"])) main <- gsub("~/","~/MEGAsync/",main)
if (grepl("cox",Sys.info()["user"])) main <- gsub("~/","~/MEGA/",main)
datadir <- paste(main,"data/",sep="")
Rdir <- paste(main,"Rcodes/",sep="")
#if (!exists(Rdir)) dir.create(Rdir)
# KUtils::pulizia(paste(main,"knitr/",sep=""),c("Rnw","bib","pdf")) #,TRUE, rm.cache=TRUE)
D <- format(Sys.Date(),"%d/%m/%Y")
getwd()
# --- (Optional) Also show overlapping group densities for A and B ---
# This is a second figure, if you'd like it:
xg <- seq(min(mu_A, mu_B) - 4, max(mu_A, mu_B) + 4, length.out = 1000)
library(ggplot2)
# --- Target CLES and implied Cohen's d ---
target_cles <- 0.75
# For two normals with equal SD, CLES = Phi(d / sqrt(2))
d <- sqrt(2) * qnorm(target_cles)
# --- Choose group parameters consistent with that CLES ---
mu_A <- 0
sd_A <- 1
mu_B <- mu_A - d * sd_A   # so that P(A > B) = 0.75
# Distribution of D = A - B is Normal(mean = mu_A - mu_B, sd = sqrt(sd_A^2 + sd_B^2))
mu_D  <- mu_A - mu_B
sd_D  <- sqrt(sd_A^2 + sd_A^2)  # equal SDs assumed
# Grid for the difference distribution
x <- seq(mu_D - 4*sd_D, mu_D + 4*sd_D, length.out = 1000)
dens <- dnorm(x, mean = mu_D, sd = sd_D)
df <- data.frame(x = x, dens = dens, region = ifelse(x > 0, "A > B", "A ≤ B"))
# Compute (and check) CLES analytically
cles_calc <- 1 - pnorm(0, mean = mu_D, sd = sd_D)  # should be ~0.75
p <- ggplot(df, aes(x, dens, fill = region)) +
geom_area(alpha = 0.6) +
geom_line(color = "black") +
geom_vline(xintercept = 0, linetype = 2) +
labs(
title = sprintf("P(A > B) = %.2f  |  Cohen's d ≈ %.2f", cles_calc, d),
x = "Pairwise difference: A − B",
y = "Density",
fill = NULL
) +
theme_minimal(base_size = 15) +
theme(
legend.position = "top",
plot.title = element_text(face = "bold"),
axis.title = element_text(size = 16),
axis.text = element_text(size = 16)
)
# Show plot
print(p)
p
# --- (Optional) Also show overlapping group densities for A and B ---
# This is a second figure, if you'd like it:
xg <- seq(min(mu_A, mu_B) - 4, max(mu_A, mu_B) + 4, length.out = 1000)
df_g <- rbind(
data.frame(x = xg, dens = dnorm(xg, mu_A, sd_A), group = "A"),
data.frame(x = xg, dens = dnorm(xg, mu_B, sd_A), group = "B")
)
p2 <- ggplot(df_g, aes(x, dens, color = group)) +
geom_line(linewidth = 1) +
labs(
title = "Group Densities Consistent with CLES ≈ 0.75 (P(A > B))",
subtitle = sprintf("Means: μA=%.2f, μB=%.2f (sd=1), d≈%.2f", mu_A, mu_B, d),
x = "Value",
y = "Density",
color = NULL
) +
theme_minimal(base_size = 15) +
theme(
legend.position = "top",
plot.title = element_text(face = "bold"),
axis.title = element_text(size = 16),
axis.text = element_text(size = 16)
)
p2
load( paste0(datadir, "ALL.rda") )
rm(list=ls())
main <- "/Users/ambraperugini/Documents/Work/Conferences/Presentazioni/AIP_2025/"
datadir <- paste0(main,"data/")
esegui <- FALSE
SEED <- 1
sninvpar <- function( mu=0, sigma=1, xi=NULL, omega=NULL, alpha=0 ) {
if (is.null(omega)) {
delta <- alpha/sqrt(1+alpha^2)
omega2 <- sigma^2 / ( 1 - (2*delta^2) / pi )
omega <- sqrt( omega2 )
}
if (is.null(xi)) {
delta <- alpha/sqrt(1+alpha^2)
xi <- mu - omega * delta * sqrt( 2/pi )
}
return( list( xi = xi, omega = omega, alpha = alpha ) )
}
load( paste0(datadir, "ALL.rda") )
load( paste0(datadir, "ALL_500.rda") )
ALL$bias_cles <- with(ALL, cles - true_overlap )
View(ALL)
library(psych)
ALL$true_cles <- d_to_overlap(ALL$true_d)
ALL$bias_cles <- with(ALL, cles - true_cles )
ALL$true_cles <- d_to_overlap(ALL$true_d)
library(effectsize)
ALL$true_cles <- d_to_overlap(ALL$true_d)
ALL$bias_cles <- with(ALL, cles - true_cles )
ALL$rbias_cles <- with( ALL, (cles - true_overlap)/true_cles )
knitr::opts_chunk$set(echo = FALSE, cache = TRUE, warning = FALSE, message = FALSE)
rm(list=ls())
library(kableExtra)
library(readxl)
library(ggplot2)
library(brms)
library(brms)
library(dplyr)
library(tibble)
library(lme4)
library(lmerTest)
add_gruppo <- function(df, group_info) {
df <- df %>%
left_join(group_info, by = "Nome", suffix = c("", "_ref")) %>%
mutate(Gruppo = ifelse(is.na(Gruppo_ref), Gruppo, Gruppo_ref)) %>%
select(-Gruppo_ref)
return(df)
}
QAR_pre <- data.frame(read_excel("QUEST_2025/QAR_PRE_AGG.xlsx"))
QAR_pre <- data.frame(read_excel("QUEST_2025/QAR_PRE_AGG.xlsx"))
QAR_post_Genere <- data.frame(read_excel("QUEST_2025/QAR_POST_AGG.xlsx"))
QAR_post_Genere <- data.frame(read_excel("QUEST_2025/QAR_POST_AGG.xlsx"))
QAR_post <- QAR_post_Genere[, - 26]
group_info_pre <- QAR_pre %>% select(Nome, Gruppo)
group_info_post <- QAR_post %>% select(Nome, Gruppo)
QAR_tot<-rbind(QAR_pre,QAR_post)
QAR_tot<-QAR_tot[!(QAR_tot$ID=="29585"),] ## elimino Eleonora
QAR_tot$ID<-as.numeric(QAR_tot$ID)
start = which(colnames(QAR_tot)=="Q01_1..per.nulla.del.tutto")
end = which(colnames(QAR_tot)=="Q14_14..per.nulla.del.tutto")
for(i in start:end){
colnames(QAR_tot)[i] = substr(colnames(QAR_tot)[i],1,3)
QAR_tot[,i] = as.numeric(QAR_tot[,i])
}
QAR_tot$QAR_Ans<-rowSums(QAR_tot[,c(13,14,17,19,20,23,25)],na.rm = TRUE)
QAR_tot$QAR_Res<-rowSums(QAR_tot[,c(12,15,16,18,21,22,24)],na.rm = TRUE)
QAR_tot$QAR_Ans_z<-(QAR_tot$QAR_Ans-11.86)/3.59
QAR_tot$QAR_Res_z<-(QAR_tot$QAR_Res-26.61)/3.60
QAS_pre <- data.frame(read_excel("QUEST_2025/QAS_PRE.xlsx"))
QAS_post <- data.frame(read_excel("QUEST_2025/QAS_POST.xlsx"))
QAS_post <- data.frame(read_excel("QUEST_2025/QAS_POST.xlsx"))
QAS_pre <- add_gruppo(QAS_pre, group_info_pre)
QAS_post <- add_gruppo(QAS_post, group_info_post)
QAS_pre$Fase <- "PRE"
QAS_post$Fase <- "POST"
QAS_tot<-rbind(QAS_pre,QAS_post)
QAS_tot$ID<-as.numeric(QAS_tot$ID)
start = which(colnames(QAS_tot)=="Q00_1..mai.sempre")
end = which(colnames(QAS_tot)=="Q18_50..mai.sempre")
for (i in seq_along(start:end)) {
col_index <- start + i - 1
new_name <- paste0("Q", formatC(i, width = 2, flag = "0"))  # Q01, Q02, ...
colnames(QAS_tot)[col_index] <- new_name
QAS_tot[, col_index] <- as.numeric(QAS_tot[, col_index])
}
# da invertire
reverseitems = c("Q02","Q05","Q08","Q09","Q10","Q12","Q17")
for(i in reverseitems){
QAS_tot[,i] = 6 - QAS_tot[,i]
}
QAS_tot$QAS_Os<-rowSums(QAS_tot[,c(11,19,21,27)],na.rm = TRUE)
QAS_tot$QAS_Es<-rowSums(QAS_tot[,c(12,23,25,29)],na.rm = TRUE)
QAS_tot$QAS_Ss<-rowSums(QAS_tot[,c(13,14,18,26)],na.rm = TRUE)
QAS_tot$QAS_As<-rowSums(QAS_tot[,c(15,20,22,28)],na.rm = TRUE)
QAS_tot$QAS_SMs<-rowSums(QAS_tot[,c(16,17,24,30)],na.rm = TRUE)
QAS_tot$QAS_O<-QAS_tot$QAS_Os/4
QAS_tot$QAS_E<-QAS_tot$QAS_Es/4
QAS_tot$QAS_A<-QAS_tot$QAS_As/4
QAS_tot$QAS_S<-QAS_tot$QAS_Ss/4
QAS_tot$QAS_SM<-QAS_tot$QAS_SMs/4
QAS_tot$QAS_TOTs<-rowSums(QAS_tot[,36:40],na.rm = TRUE)
QAS_tot$QAS_TOT<-QAS_tot$QAS_TOTs/5
QAS_tot$QAS_O_z <- (QAS_tot$QAS_O - 3.20) / 0.57
QAS_tot$QAS_E_z <- (QAS_tot$QAS_E - 3.95) / 0.66
QAS_tot$QAS_A_z <- (QAS_tot$QAS_A - 3.52) / 0.66
QAS_tot$QAS_S_z <- (QAS_tot$QAS_S - 3.97) / 0.68
QAS_tot$QAS_SM_z <- (QAS_tot$QAS_SM - 3.18) / 0.74
QAS_tot$QAS_TOT_z <- (QAS_tot$QAS_TOT - 3.58) / 0.42
QAES_pre <- data.frame(read_excel("QUEST_2025/QAES_PRE.xlsx"))
QAES_pre <- add_gruppo(QAES_pre, group_info_pre)
QAES_post <- add_gruppo(QAES_post, group_info_post)
QAES_pre$Fase <- "PRE"
QAES_post <- data.frame(read_excel("QUEST_2025/QAES_POST.xlsx"))
QAES_post <- add_gruppo(QAES_post, group_info_post)
QAES_pre$Fase <- "PRE"
QAES_post$Fase <- "POST"
QAES_tot<-rbind(QAES_pre,QAES_post)
QAES_tot <- cbind(
QAES_tot[1:10],
Completo = rep(NA, nrow(QAES_tot)),
QAES_tot[11:ncol(QAES_tot)]
)
QAES_tot<-QAES_tot[!(QAES_tot$ID=="29585"),] ## elimino Eleonora
QAES_tot$ID<-as.numeric(QAES_tot$ID)
start = which(colnames(QAES_tot)=="Q00_1..mai.sempre")
end = which(colnames(QAES_tot)=="Q18_20..mai.sempre")
for(i in start:end){
colnames(QAES_tot)[i] = substr(colnames(QAES_tot)[i],1,3)
QAES_tot[,i] = as.numeric(QAES_tot[,i])
}
QAES_tot$QAES_Pos<-rowSums(QAES_tot[,c(12,15,17,18,20,22,23,26,28,30)],na.rm = TRUE) / 10
QAES_tot$QAES_Neg<-rowSums(QAES_tot[,c(13,14,16,19,21,24,25,27,29,31)],na.rm = TRUE) / 10
QAES_tot$QAES_Pos_z<-(QAES_tot$QAES_Pos -  3.55) / 0.61
QAES_tot$QAES_Neg_z<-(QAES_tot$QAES_Neg - 2.68) /  0.74
QAEA_pre <- data.frame(read_excel("QUEST_2025/QAEA_PRE.xlsx"))
QAEA_post <- data.frame(read_excel("QUEST_2025/QAEA_POST.xlsx"))
QAEA_pre <- add_gruppo(QAEA_pre, group_info_pre)
QAEA_post <- add_gruppo(QAEA_post, group_info_post)
QAEA_pre$Fase <- "PRE"
QAEA_post$Fase <- "POST"
QAEA_tot<-rbind(QAEA_pre,QAEA_post)
QAEA_tot <- cbind(
QAEA_tot[1:10],
Completo = rep(NA, nrow(QAEA_tot)),
QAEA_tot[11:ncol(QAEA_tot)]
)
QAEA_tot<-QAEA_tot[!(QAEA_tot$ID=="29585"),] ## elimino Eleonora
QAEA_tot$ID<-as.numeric(QAEA_tot$ID)
start = which(colnames(QAEA_tot)=="Q00_1..mai.sempre")
end = which(colnames(QAEA_tot)=="Q18_20..mai.sempre")
for(i in start:end){
colnames(QAEA_tot)[i] = substr(colnames(QAEA_tot)[i],1,3)
QAEA_tot[,i] = as.numeric(QAEA_tot[,i])
}
QAEA_tot$QAEA_Pos<-rowSums(QAEA_tot[,c(12,15,17,18,20,22,23,26,28,30)],na.rm = TRUE) / 10
QAEA_tot$QAEA_Neg<-rowSums(QAEA_tot[,c(13,14,16,19,21,24,25,27,29,31)],na.rm = TRUE) / 10
QAEA_tot$QAEA_Pos_z<-(QAEA_tot$QAEA_Pos -   3.36) /  0.76
QAEA_tot$QAEA_Neg_z<-(QAEA_tot$QAEA_Neg -  2.48) /  0.90
BESSI_pre <- data.frame(read_excel("QUEST_2025/BESSI_PRE.xlsx"))
BESSI_post <- data.frame(read_excel("QUEST_2025/BESSI_POST.xlsx"))
BESSI_pre <- add_gruppo(BESSI_pre, group_info_pre)
BESSI_post <- add_gruppo(BESSI_post, group_info_post)
BESSI_pre$Fase <- "PRE"
BESSI_post$Fase <- "POST"
BESSI_tot<-rbind(BESSI_pre,BESSI_post)
BESSI_tot <- cbind(
BESSI_tot[1:10],
Completo = rep(NA, nrow(BESSI_tot)),
BESSI_tot[11:ncol(BESSI_tot)]
)
BESSI_tot<-BESSI_tot[!(BESSI_tot$ID=="29585"),] ## elimino Eleonora
BESSI_tot$ID<-as.numeric(BESSI_tot$ID)
start = which(colnames(BESSI_tot)=="Q00_1..Per.niente.bene.Benissimo")
end = which(colnames(BESSI_tot)=="Q18_20..Per.niente.bene.Benissimo")
for(i in start:end){
colnames(BESSI_tot)[i] = substr(colnames(BESSI_tot)[i],1,3)
BESSI_tot[,i] = as.numeric(BESSI_tot[,i])
}
BESSI_tot$BESSI_Self_M<-rowSums(BESSI_tot[,c(12,17,22,27)],na.rm = TRUE)/4
BESSI_tot$BESSI_Soc_Eng<-rowSums(BESSI_tot[,c(13,18,23,28)],na.rm = TRUE)/4
BESSI_tot$BESSI_Coop<-rowSums(BESSI_tot[,c(14,19,24,29)],na.rm = TRUE)/4
BESSI_tot$BESSI_Em_Res<-rowSums(BESSI_tot[,c(15,20,25,30)],na.rm = TRUE)/4
BESSI_tot$BESSI_Innov<-rowSums(BESSI_tot[,c(16,21,26,31)],na.rm = TRUE)/4
BESSI_tot$BESSI_TOT<-rowSums(BESSI_tot[,c(32:36)],na.rm = TRUE)/5
BESSI_tot$BESSI_Self_M_z <- (BESSI_tot$BESSI_Self_M - 3.35) / 0.68
BESSI_tot$BESSI_Soc_Eng_z <- (BESSI_tot$BESSI_Soc_Eng - 3.18) / 0.72
BESSI_tot$BESSI_Coop_z <- (BESSI_tot$BESSI_Coop - 3.52) / 0.63
BESSI_tot$BESSI_Em_Res_z <- (BESSI_tot$BESSI_Em_Res - 2.92) / 0.74
BESSI_tot$BESSI_Innov_z <- (BESSI_tot$BESSI_Innov - 3.08) / 0.66
BESSI_tot$BESSI_TOT_z <- (BESSI_tot$BESSI_TOT - 3.2) / 0.44
QAS<-QAS_tot[,c(6:9,43:48)]
QAR<-QAR_tot[,c(6:9,28,29)]
QAES<-QAES_tot[,c(6:9,32:35)]
QAEA<-QAEA_tot[,c(6:9,32:35)]
BESSI<-BESSI_tot[,c(6:9,32:43)]
QAS_pre <- data.frame(read_excel("QUEST_2025/QAS_50_PRE.xlsx"))
QAS_pre <- data.frame(read_excel("QUEST_2025/QAS_50_PRE.xlsx"))
QAS_post <- data.frame(read_excel("QUEST_2025/QAS_50_POST.xlsx"))
QAS_pre <- add_gruppo(QAS_pre, group_info_pre)
QAS_pre <- add_gruppo(QAS_pre, group_info_pre)
QAS_post <- add_gruppo(QAS_post, group_info_post)
QAS_pre$Fase <- "PRE"
QAS_post$Fase <- "POST"
QAS_tot<-rbind(QAS_pre,QAS_post)
QAS_tot<-QAS_tot[!(QAS_tot$ID=="28816"),] ## elimino Paola
QAS_tot$ID<-as.numeric(QAS_tot$ID)
start = which(colnames(QAS_tot)=="Q00_1..mai.sempre")
end = which(colnames(QAS_tot)=="Q46_50..mai.sempre")
for (i in seq_along(start:end)) {
col_index <- start + i - 1
new_name <- paste0("Q", formatC(i, width = 2, flag = "0"))  # Q01, Q02, ...
colnames(QAS_tot)[col_index] <- new_name
QAS_tot[, col_index] <- as.numeric(QAS_tot[, col_index])
}
# da invertire
reverseitems = c("Q04","Q05","Q06","Q13","Q14","Q19","Q20","Q22","Q23","Q24","Q25","Q26","Q29","Q30","Q32","Q35","Q38","Q40","Q46")
for(i in reverseitems){
QAS_tot[,i] = 6 - QAS_tot[,i]
}
QAS_tot$QAS_Os<-rowSums(QAS_tot[,c(11,15,13,32,37,42,44,53,56,57)],na.rm = TRUE)
QAS_tot$QAS_Es<-rowSums(QAS_tot[,c(16,18,22,38,40,46,47,48,51,59)],na.rm = TRUE)
QAS_tot$QAS_As<-rowSums(QAS_tot[,c(13,24,25,31,34,35,36,45,54,58)],na.rm = TRUE)
QAS_tot$QAS_SMs<-rowSums(QAS_tot[,c(14,26,27,28,29,43,49,50,55,60)],na.rm = TRUE)
QAS_tot$QAS_O<-QAS_tot$QAS_Os/10
QAS_tot$QAS_E<-QAS_tot$QAS_Es/10
QAS_tot$QAS_A<-QAS_tot$QAS_As/10
QAS_tot$QAS_S<-QAS_tot$QAS_Ss/10
QAS_tot$QAS_SM<-QAS_tot$QAS_SMs/10
QAS_tot$QAS_TOTs<-rowSums(QAS_tot[,66:70],na.rm = TRUE)
QAS_tot$QAS_S<-QAS_tot$QAS_Ss/10
